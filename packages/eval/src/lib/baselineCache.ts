/**
 * Cache for single-model baseline results.
 *
 * Stores pre-computed evaluation results for the single-model baseline
 * (response[0] from the ensemble cache, evaluated once). The cache is
 * sample-size independent â€” it stores results for ALL cached questions.
 * quick-eval filters to the sampled question IDs at load time.
 *
 * Cache key: `{model}_{dataset}.json`
 * Cache dir: `packages/eval/.cache/baselines/`
 *
 * Generated by `generate-cache` alongside ensemble responses.
 * Committed to the repo so CI never needs to run single baseline.
 */
import { resolve, dirname } from 'node:path';
import { fileURLToPath } from 'node:url';
import { fileExists, readJsonFile, writeJsonFile } from './io.js';
import type { PromptRunResult } from '../types.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const CACHE_DIR = resolve(__dirname, '../../.cache/baselines');

export interface BaselineCacheFile {
  model: string;
  dataset: string;
  createdAt: string;
  entries: Array<{ questionId: string; result: PromptRunResult }>;
}

function cacheKey(model: string, dataset: string): string {
  const safeModel = model.replace(/[/:]/g, '_');
  return `${safeModel}_${dataset}.json`;
}

function cachePath(model: string, dataset: string): string {
  return resolve(CACHE_DIR, cacheKey(model, dataset));
}

/**
 * Load pre-computed single baseline results as a Map<questionId, PromptRunResult>.
 * Returns null if no cache file exists.
 */
export async function loadCachedBaseline(
  model: string,
  dataset: string,
): Promise<Map<string, PromptRunResult> | null> {
  const path = cachePath(model, dataset);
  if (!(await fileExists(path))) return null;
  try {
    const file = await readJsonFile<BaselineCacheFile>(path);
    const map = new Map<string, PromptRunResult>();
    for (const entry of file.entries) {
      map.set(entry.questionId, entry.result);
    }
    return map;
  } catch {
    return null;
  }
}

/**
 * Save pre-computed single baseline results. Overwrites any existing cache.
 */
export async function saveCachedBaseline(
  model: string,
  dataset: string,
  results: Array<{ questionId: string; result: PromptRunResult }>,
): Promise<void> {
  const path = cachePath(model, dataset);
  const file: BaselineCacheFile = {
    model,
    dataset,
    createdAt: new Date().toISOString(),
    entries: results,
  };
  await writeJsonFile(path, file);
}
